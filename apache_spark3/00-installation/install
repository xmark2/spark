#!/bin/bash

current_date=$(date +%Y-%m-%d__%H:%M:%S)
logfile=$(pwd)/"$0".log
env_setup_file=$(pwd)/env_setup.txt
current_dir=$(pwd)

java --version

if [ $? -ne 0 ]; then
  for package in default-jre openjdk-11-jre-headless;
  do
    sudo apt install $package -y
    echo "$current_date -- The installation of $package was successful.">>$logfile
    echo "The new command is available here:"
    which $package
  done

  java version
else
  echo "java's already installed:"
  which java
fi

which scala

if [ $? -ne 0 ]; then
  for package in curl mlocate git scala;
  do
    sudo apt install $package -y
    echo "$current_date -- The installation of $package was successful.">>$logfile
    echo "The new command is available here:"
    which $package
  done
else
  echo "scala's already installed:"
  which scala
fi

which jupyter

if [ $? -ne 0 ]
then
    sudo apt  install jupyter-core
    echo "$current_date -- The installation of jupyter was successful.">>$logfile
else
  echo "jupyter's already installed:"
  which jupyter
fi

if [ -d "/mnt/spark" ]
then
  echo "spark's already installed:"
  echo "/mnt/spark"
else
  if test -f ~/"spark-3.5.1-bin-hadoop3.tgz"
  then
    echo "spark's already downloaded"
  else
    cd ~
    wget https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz
    tar xvf spark-3.5.1-bin-hadoop3.tgz
    sudo mv spark-3.5.1-bin-hadoop3 /mnt/spark
    cd $current_dir
    echo "$current_date -- The installation of spark was successful.">>$logfile
  fi
fi

#spark environment

#sudo nano ~/.bashrc

echo "Setup spark environment">$env_setup_file
echo "------------------">>$env_setup_file
echo "gedit ~/.profile">>$env_setup_file
echo "Add the following lines to  end of .bashrc file">>$env_setup_file
echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64">>$env_setup_file
echo "export SPARK_HOME=/mnt/spark">>$env_setup_file
echo "export PATH=\$PATH:\$SPARK_HOME/bin:\$SPARK_HOME/sbin">>$env_setup_file
echo "--RUNNING----------------">>$env_setup_file
echo "spark-shell">>$env_setup_file
echo "pyspark">>$env_setup_file
#echo "start-master.sh"
#echo "stop-master.sh"

#sudo apt install curl mlocate git scala -y

### Remove java jdk
#sudo apt-get purge openjdk*

### set up JAVA_HOME environment variable
#sudo update-alternatives --config java
#sudo nano /etc/environment